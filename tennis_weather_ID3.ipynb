{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQl6bU7aLnXYtCAOhIC2Yw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarveshrastogi1/ML_Lab_1bm22cs247/blob/main/tennis_weather_ID3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQk84d40AF78",
        "outputId": "2504043c-1798-4413-9cc5-bc4307f28a0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learned Decision Tree using ID3:\n",
            "{'outlook': {'overcast': 'yes', 'rainy': {'windy': {False: 'yes', True: 'no'}}, 'sunny': {'humidity': {'high': 'no', 'normal': 'yes'}}}}\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Read the dataset from CSV\n",
        "df = pd.read_csv(\"/content/tennis.csv\")\n",
        "\n",
        "# Define the entropy calculation function\n",
        "def entropy(target_col):\n",
        "    elements, counts = np.unique(target_col, return_counts=True)\n",
        "    ent = 0\n",
        "    for i in range(len(elements)):\n",
        "        probability = counts[i] / np.sum(counts)\n",
        "        ent -= probability * np.log2(probability)\n",
        "    return ent\n",
        "\n",
        "# Define function to calculate information gain for an attribute\n",
        "def info_gain(data, split_attribute, target_attr):\n",
        "    # Total entropy for the current dataset\n",
        "    total_entropy = entropy(data[target_attr])\n",
        "\n",
        "    # Values and corresponding counts for the split attribute\n",
        "    vals, counts = np.unique(data[split_attribute], return_counts=True)\n",
        "\n",
        "    # Calculate the weighted entropy for the split attribute\n",
        "    weighted_entropy = sum(\n",
        "        (counts[i] / np.sum(counts)) * entropy(data[data[split_attribute] == vals[i]][target_attr])\n",
        "        for i in range(len(vals))\n",
        "    )\n",
        "\n",
        "    # Information Gain is the difference in entropy\n",
        "    gain = total_entropy - weighted_entropy\n",
        "    return gain\n",
        "\n",
        "# Implement the recursive ID3 algorithm\n",
        "def id3(data, original_data, features, target_attr, parent_class=None):\n",
        "    # If dataset is empty, return the mode target feature value in the original dataset\n",
        "    if data.empty:\n",
        "        return np.unique(original_data[target_attr])[np.argmax(np.unique(original_data[target_attr], return_counts=True)[1])]\n",
        "\n",
        "    # If all target_values have the same value, return that value\n",
        "    elif len(np.unique(data[target_attr])) == 1:\n",
        "        return np.unique(data[target_attr])[0]\n",
        "\n",
        "    # If the feature space is empty, return the parent node's class value (mode target feature value)\n",
        "    elif len(features) == 0:\n",
        "        return parent_class\n",
        "    else:\n",
        "        # Determine the parent class (mode) for the current node\n",
        "        parent_class = np.unique(data[target_attr])[np.argmax(np.unique(data[target_attr], return_counts=True)[1])]\n",
        "\n",
        "        # Select the feature which best splits the dataset based on information gain\n",
        "        gains = [info_gain(data, feature, target_attr) for feature in features]\n",
        "        best_feature_index = np.argmax(gains)\n",
        "        best_feature = features[best_feature_index]\n",
        "\n",
        "        # Create the tree structure. The root is the best feature.\n",
        "        tree = {best_feature: {}}\n",
        "\n",
        "        # Remove the best feature from the feature space\n",
        "        remaining_features = [feat for feat in features if feat != best_feature]\n",
        "\n",
        "        # Grow a branch under the root node for each value of the best feature\n",
        "        for value in np.unique(data[best_feature]):\n",
        "            sub_data = data[data[best_feature] == value]\n",
        "            subtree = id3(sub_data, original_data, remaining_features, target_attr, parent_class)\n",
        "            tree[best_feature][value] = subtree\n",
        "        return tree\n",
        "\n",
        "# Specify the target attribute and feature names.\n",
        "# Adjust 'Play' to match your CSV's column name for the target variable if different.\n",
        "target_attribute = \"play\"\n",
        "features = list(df.columns)\n",
        "features.remove(target_attribute)\n",
        "\n",
        "# Build the decision tree\n",
        "decision_tree = id3(df, df, features, target_attribute)\n",
        "\n",
        "# Output the resulting decision tree\n",
        "print(\"Learned Decision Tree using ID3:\")\n",
        "print(decision_tree)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install graphviz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJQXnwjPBXd6",
        "outputId": "7448c762-dc2f-4d2d-9c0a-c8298ac217dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (0.20.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from graphviz import Digraph\n",
        "\n",
        "# Read the dataset from CSV\n",
        "df = pd.read_csv(\"tennis.csv\")\n",
        "\n",
        "# Debug: Print out the columns to ensure the target column name is correct.\n",
        "print(\"Columns in dataset:\", df.columns.tolist())\n",
        "\n",
        "# Update this if your target column header is different.\n",
        "target_attribute = \"play\"\n",
        "if target_attribute not in df.columns:\n",
        "    raise ValueError(f\"Target column '{target_attribute}' not found in the dataset. Please check the header names.\")\n",
        "\n",
        "features = list(df.columns)\n",
        "features.remove(target_attribute)\n",
        "\n",
        "# Function to calculate entropy\n",
        "def entropy(target_col):\n",
        "    elements, counts = np.unique(target_col, return_counts=True)\n",
        "    ent = 0\n",
        "    for i in range(len(elements)):\n",
        "        probability = counts[i] / np.sum(counts)\n",
        "        ent -= probability * np.log2(probability)\n",
        "    return ent\n",
        "\n",
        "# Function to calculate information gain for an attribute\n",
        "def info_gain(data, split_attribute, target_attr):\n",
        "    total_entropy = entropy(data[target_attr])\n",
        "    vals, counts = np.unique(data[split_attribute], return_counts=True)\n",
        "    weighted_entropy = sum(\n",
        "        (counts[i] / np.sum(counts)) * entropy(data[data[split_attribute] == vals[i]][target_attr])\n",
        "        for i in range(len(vals))\n",
        "    )\n",
        "    gain = total_entropy - weighted_entropy\n",
        "    return gain\n",
        "\n",
        "# ID3 recursive algorithm\n",
        "def id3(data, original_data, features, target_attr, parent_class=None):\n",
        "    # If dataset is empty, return the mode target feature value of the original dataset.\n",
        "    if data.empty:\n",
        "        return np.unique(original_data[target_attr])[np.argmax(np.unique(original_data[target_attr], return_counts=True)[1])]\n",
        "\n",
        "    # If all target_values have the same value, return that value.\n",
        "    elif len(np.unique(data[target_attr])) == 1:\n",
        "        return np.unique(data[target_attr])[0]\n",
        "\n",
        "    # If the feature space is empty, return the parent node's class value.\n",
        "    elif len(features) == 0:\n",
        "        return parent_class\n",
        "    else:\n",
        "        # Determine the parent class (mode) for the current node.\n",
        "        parent_class = np.unique(data[target_attr])[np.argmax(np.unique(data[target_attr], return_counts=True)[1])]\n",
        "\n",
        "        # Select the feature which best splits the dataset.\n",
        "        gains = [info_gain(data, feature, target_attr) for feature in features]\n",
        "        best_feature_index = np.argmax(gains)\n",
        "        best_feature = features[best_feature_index]\n",
        "\n",
        "        # Create the tree structure. The root is the best feature.\n",
        "        tree = {best_feature: {}}\n",
        "\n",
        "        # Remove the best feature from the list of available features.\n",
        "        remaining_features = [feat for feat in features if feat != best_feature]\n",
        "\n",
        "        # Grow a branch under the root node for each value of the best feature.\n",
        "        for value in np.unique(data[best_feature]):\n",
        "            sub_data = data[data[best_feature] == value]\n",
        "            subtree = id3(sub_data, original_data, remaining_features, target_attr, parent_class)\n",
        "            tree[best_feature][value] = subtree\n",
        "        return tree\n",
        "\n",
        "# Build the decision tree\n",
        "decision_tree = id3(df, df, features, target_attribute)\n",
        "print(\"Learned Decision Tree using ID3:\")\n",
        "print(decision_tree)\n",
        "\n",
        "# -----------------------------------------------\n",
        "# Visualization using Graphviz\n",
        "# -----------------------------------------------\n",
        "\n",
        "def add_nodes_edges(tree, dot=None, parent=None, edge_label=\"\"):\n",
        "    \"\"\"\n",
        "    Recursively add nodes and edges from the decision tree dictionary into the Graphviz Digraph.\n",
        "    \"\"\"\n",
        "    if dot is None:\n",
        "        dot = Digraph()\n",
        "\n",
        "    # If the current tree is not a dictionary, it is a leaf node.\n",
        "    if not isinstance(tree, dict):\n",
        "        node_id = str(id(tree))\n",
        "        dot.node(node_id, label=str(tree), shape=\"box\", style=\"filled\", color=\"lightgray\")\n",
        "        if parent is not None:\n",
        "            dot.edge(parent, node_id, label=edge_label)\n",
        "        return dot\n",
        "\n",
        "    # Since tree is a dictionary, it has one key which is the decision attribute.\n",
        "    root_attr = list(tree.keys())[0]\n",
        "    root_id = str(id(tree))\n",
        "    dot.node(root_id, label=root_attr, shape=\"ellipse\", style=\"filled\", color=\"lightblue\")\n",
        "    if parent is not None:\n",
        "        dot.edge(parent, root_id, label=edge_label)\n",
        "\n",
        "    # For each branch, add the subtree recursively.\n",
        "    for branch_val, subtree in tree[root_attr].items():\n",
        "        add_nodes_edges(subtree, dot, parent=root_id, edge_label=str(branch_val))\n",
        "\n",
        "    return dot\n",
        "\n",
        "# Create the Graphviz Digraph from the decision tree structure.\n",
        "dot = add_nodes_edges(decision_tree)\n",
        "dot.format = 'png'\n",
        "# Save and render the tree visualization.\n",
        "dot.render(\"decision_tree\", view=True)\n",
        "\n",
        "print(\"Decision tree visualization generated and saved as 'decision_tree.png'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UUc6mgpBaJR",
        "outputId": "0863acc2-cb20-4a95-ede7-3416339418f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in dataset: ['outlook', 'temp', 'humidity', 'windy', 'play']\n",
            "Learned Decision Tree using ID3:\n",
            "{'outlook': {'overcast': 'yes', 'rainy': {'windy': {False: 'yes', True: 'no'}}, 'sunny': {'humidity': {'high': 'no', 'normal': 'yes'}}}}\n",
            "Decision tree visualization generated and saved as 'decision_tree.png'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from graphviz import Digraph\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"tennis.csv\")\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "target = \"play\"\n",
        "if target not in df.columns:\n",
        "    raise ValueError(f\"Target column '{target}' not found.\")\n",
        "features = list(df.columns)\n",
        "features.remove(target)\n",
        "\n",
        "# Calculate entropy\n",
        "def entropy(col):\n",
        "    elems, counts = np.unique(col, return_counts=True)\n",
        "    return -sum((c/np.sum(counts)) * np.log2(c/np.sum(counts)) for c in counts)\n",
        "\n",
        "# Calculate information gain\n",
        "def info_gain(data, attr, target):\n",
        "    total = entropy(data[target])\n",
        "    vals, counts = np.unique(data[attr], return_counts=True)\n",
        "    weighted = sum((counts[i]/np.sum(counts)) * entropy(data[data[attr]==vals[i]][target])\n",
        "                   for i in range(len(vals)))\n",
        "    return total - weighted\n",
        "\n",
        "# ID3 algorithm\n",
        "def id3(data, orig, feats, target, parent_class=None):\n",
        "    if data.empty:\n",
        "        return np.unique(orig[target])[np.argmax(np.unique(orig[target], return_counts=True)[1])]\n",
        "    if len(np.unique(data[target])) == 1:\n",
        "        return np.unique(data[target])[0]\n",
        "    if not feats:\n",
        "        return parent_class\n",
        "    parent_class = np.unique(data[target])[np.argmax(np.unique(data[target], return_counts=True)[1])]\n",
        "    best = feats[np.argmax([info_gain(data, f, target) for f in feats])]\n",
        "    tree = {best: {}}\n",
        "    remaining = [f for f in feats if f != best]\n",
        "    for val in np.unique(data[best]):\n",
        "        subtree = id3(data[data[best]==val], orig, remaining, target, parent_class)\n",
        "        tree[best][val] = subtree\n",
        "    return tree\n",
        "\n",
        "tree = id3(df, df, features, target)\n",
        "print(\"Decision Tree:\", tree)\n",
        "\n",
        "# Visualization\n",
        "def add_nodes_edges(tree, dot=None, parent=None, edge_label=\"\"):\n",
        "    dot = dot or Digraph()\n",
        "    if not isinstance(tree, dict):\n",
        "        nid = str(id(tree))\n",
        "        dot.node(nid, label=str(tree), shape=\"box\", style=\"filled\", color=\"lightgray\")\n",
        "        if parent: dot.edge(parent, nid, label=edge_label)\n",
        "        return dot\n",
        "    root = list(tree.keys())[0]\n",
        "    rid = str(id(tree))\n",
        "    dot.node(rid, label=root, shape=\"ellipse\", style=\"filled\", color=\"lightblue\")\n",
        "    if parent: dot.edge(parent, rid, label=edge_label)\n",
        "    for branch, sub in tree[root].items():\n",
        "        add_nodes_edges(sub, dot, rid, str(branch))\n",
        "    return dot\n",
        "\n",
        "dot = add_nodes_edges(tree)\n",
        "dot.format = 'png'\n",
        "dot.render(\"decision_tree\", view=True)\n",
        "print(\"Visualization saved as 'decision_tree.png'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RikkV3ZDDXWi",
        "outputId": "145fe670-b54d-4b51-e534-23457ded6b79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns: ['outlook', 'temp', 'humidity', 'windy', 'play']\n",
            "Decision Tree: {'outlook': {'overcast': 'yes', 'rainy': {'windy': {False: 'yes', True: 'no'}}, 'sunny': {'humidity': {'high': 'no', 'normal': 'yes'}}}}\n",
            "Visualization saved as 'decision_tree.png'.\n"
          ]
        }
      ]
    }
  ]
}